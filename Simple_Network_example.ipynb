{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:13:33.990767Z",
     "start_time": "2020-03-31T16:13:33.983193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:57:19.872438Z",
     "start_time": "2020-03-31T16:57:19.862991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "from sith import SITH\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patheffects\n",
    "import seaborn as sn\n",
    "sn.set_context(\"poster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize \"Corpus\"\n",
    "\n",
    "Setup the corpus, tokenize the input, and create a list of the target letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:58:40.307065Z",
     "start_time": "2020-03-31T16:58:40.246770Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentence_enders = [\"?\", \".\", \"!\"]\n",
    "separators = [\"\\'\", \",\"]\n",
    "\n",
    "letters = list(\"abcdefghijklmnopqrstuvwxyz\".upper()) + [\"<COM>\", \"<END>\", \"<SPA>\"]\n",
    "let_to_id = {s:x for x,s in enumerate(letters)}\n",
    "id_to_let = dict([[v,k] for k,v in let_to_id.items()])\n",
    "full_text = open(\"plagueis.txt\", \"r\").read()\n",
    "full_text = full_text.upper()\n",
    "full_text = full_text.replace(\"...\", \".\")\n",
    "split_text = full_text.split()\n",
    "master_list = []\n",
    "id_list = []\n",
    "for s in split_text:\n",
    "    for l in s:\n",
    "        if l in sentence_enders:\n",
    "            master_list.append(\"<END>\")\n",
    "            id_list.append(let_to_id[\"<END>\"])\n",
    "        elif l in separators:\n",
    "            master_list.append(\"<COM>\")\n",
    "            id_list.append(let_to_id[\"<COM>\"])\n",
    "        else:\n",
    "            master_list.append(l)\n",
    "            id_list.append(let_to_id[l])\n",
    "    master_list.append(\"<SPA>\")\n",
    "    id_list.append(let_to_id[\"<SPA>\"])\n",
    "\n",
    "def tokenize(inp_list, num_tokens=10):\n",
    "    output = torch.zeros(len(inp_list), num_tokens, 1).type(torch.DoubleTensor)\n",
    "    for i, inp in enumerate(inp_list):\n",
    "        output[i, inp, 0] = 1.0\n",
    "    return output\n",
    "\n",
    "input_tokens = tokenize(id_list[:-1], len(list(let_to_id.keys())))\n",
    "#target_tokens = tokenize(id_list[1:], len(list(let_to_id.keys())))\n",
    "target_tokens = torch.DoubleTensor(id_list[1:]).view(-1, 1, 1)\n",
    "if torch.cuda.is_available():\n",
    "    input_tokens = input_tokens.cuda()\n",
    "    target_tokens = target_tokens.cuda()\n",
    "\n",
    "tokens = torch.cat((input_tokens, target_tokens), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the SITH parameters\n",
    "\n",
    "pic parameters here to be used further down in the model. The output taustars will be printed in the next cell. Change tau_0, k, c, and T_every to get the right taustars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:58:41.651040Z",
     "start_time": "2020-03-31T16:58:41.641810Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.           1.47745544   2.18287459   3.22509994   4.76494147\n",
      "   7.03998871  10.40126965  15.36741246  22.7046672   33.54513415\n",
      "  49.56144107  73.22482091 108.18641027 159.8406008  236.15736578\n",
      " 348.91198567 515.50191263 761.63110709]\n"
     ]
    }
   ],
   "source": [
    "sith_params ={\"in_features\":len(list(let_to_id.keys())),\n",
    "              \"tau_0\":1, \"k\":4,\n",
    "              \"c\":.05, \"ntau\":140, \"dt\":.1, \n",
    "              \"T_every\":8, \"alpha\":1.0}\n",
    "# This is only for making sure you pick the right parameters\n",
    "sithrep = SITH(**sith_params)\n",
    "sithrep.cuda()\n",
    "taustars = sithrep._tau_star[sith_params['k']:-sith_params['k']:sith_params['T_every']].detach().cpu().numpy()\n",
    "\n",
    "print(taustars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model\n",
    "\n",
    "Its a simple model. Takes tensor of size (batch, num_tokens) as input. Passes into SITH, then into a hidden layer. The output is passed through a log_softmax, and is of size (batch, num_tokens) predicting the next letter token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:58:42.579167Z",
     "start_time": "2020-03-31T16:58:42.565303Z"
    }
   },
   "outputs": [],
   "source": [
    "class LetterModel(torch.nn.Module):\n",
    "    def __init__(self, sith_params, num_tokens):\n",
    "        super(LetterModel, self).__init__()\n",
    "        #self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.sith = SITH(**sith_params)\n",
    "        self.sith.cuda()\n",
    "        num_taustars = self.sith._tau_star[sith_params['k']:-sith_params['k']:sith_params['T_every']].shape[0]\n",
    "        self.linear = torch.nn.Linear(num_tokens*num_taustars, num_tokens).double()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.sith.reset()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.shape[0]\n",
    "        x = F.relu(self.sith(inputs)).view(batch_size, -1)\n",
    "        x = self.linear(x)\n",
    "        log_probs = F.log_softmax(x, dim=-1)\n",
    "        return log_probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:58:43.169621Z",
     "start_time": "2020-03-31T16:58:43.162182Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LetterModel(sith_params, len(list(let_to_id.keys()))).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "loss_func = torch.nn.NLLLoss()\n",
    "input_scaling = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T17:02:34.898402Z",
     "start_time": "2020-03-31T16:58:43.745897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a9865c46934aa080325c98e14572f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "progress_bar = tqdm_notebook(range(int(epochs)))\n",
    "for e in progress_bar:\n",
    "    model.reset()\n",
    "\n",
    "    for inp_and_tok in tokens.split(20, dim=0):\n",
    "        inps = inp_and_tok[:, :-1, 0]\n",
    "        targets = inp_and_tok[:, -1, 0].type(torch.cuda.LongTensor)\n",
    "        model.zero_grad()\n",
    "        out = model(inps*input_scaling)\n",
    "        loss = loss_func(out, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.reset()\n",
    "    t = 0\n",
    "    correct = 0\n",
    "    pp = 0\n",
    "    for inp_and_tok in tokens.split(20, dim=0):\n",
    "        inps = inp_and_tok[:, :-1, 0]\n",
    "        targets = inp_and_tok[:, -1, 0].type(torch.cuda.LongTensor)\n",
    "        out = model(inps*input_scaling)\n",
    "\n",
    "        # Accuracy\n",
    "        correct += (out.argmax(-1) == targets).sum().detach().cpu().numpy()\n",
    "        t += inps.shape[0]\n",
    "\n",
    "    acc = correct/t\n",
    "    progress_bar.set_description(\"%i: Acc: %0.4f\" % (e, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the finished model\n",
    "\n",
    "Prints out the most likely letter to occur when taking in the last letter as input. This cell is just a proof of concept that the model is working at all. \n",
    "\n",
    "This cell DOES NOT pass in the last predicted letter as inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T16:57:31.716633Z",
     "start_time": "2020-04-01T16:57:31.562319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID<SPA>YOU<SPA>EVER<SPA>HEARETHE<SPA>TRAGEDY<SPA>OF<SPA>DARTH<SPA>PLAGUEIS<SPA>THE<SPA>WISE<END><SPA>I<SPA>THOUGHT<SPA>NOT<END><SPA>IT<COM>S<SPA>NOT<SPA>AESOTRY<SPA>THE<SPA>JEDI<SPA>WOULD<SPA>TELL<SPA>YOU<END><SPA>IT<COM>S<SPA>A<SPA>SITH<SPA>LEGEND<END><SPA>DARTH<SPA>PLAGUEIS<SPA>WAS<SPA>A<SPA>DARK<SPA>LORD<SPA>OF<SPA>THE<SPA>SITH<COM><SPA>SO<SPA>POWERFUL<SPA>AND<SPA>SO<SPA>WISE<SPA>HE<SPA>COULD<SPA>USE<SPA>THE<SPA>FORCE<SPA>TOEINFLUENCE<SPA>THE<SPA>MIDICHLORIANS<SPA>TOECREATE<SPA>LIFE<END>EHE<SPA>HAD<SPA>SUCH<SPA>AAKNOWLEDGE<SPA>OF<SPA>THE<SPA>DARK<SPA>SIDE<SPA>THAT<SPA>HE<SPA>COULDEEVEN<SPA>KEEP<SPA>THE<SPA>ONES<SPA>HE<SPA>CARED<SPA>ABOUT<SPA>FROM<SPA>DYING<END><SPA>THE<SPA>DARK<SPA>SIDE<SPA>OF<SPA>THE<SPA>FORCE<SPA>IS<SPA>A<SPA>PATHWAY<SPA>TO<SPA>MANY<SPA>ABILITIEESSOME<SPA>CONSIDERTTOEBE<SPA>UNNATURAL<END><SPA>HE<SPA>BECAME<SPA>SO<SPA>POWERFUL<END><SPA>THE<SPA>ONLY<SPA>THING<SPA>HE<SPA>WAS<SPA>AFRAID<SPA>OF<SPA>WAS<SPA>LOSING<SPA>HIS<SPA>POWER<COM><SPA>WHICHHEVENTUALLY<COM><SPA>OF<SPA>COURSE<COM><SPA>HE<SPA>DID<END><SPA>UNFORTUNATELY<COM><SPA>HE<SPA>TAUGHT<SPA>HIS<SPA>APPRENTICE<SPA>EVERYTHING<SPA>HE<SPA>KNEW<COM><SPA>THEN<SPA>HIS<SPA>APPRENTICE<SPA>KILLED<SPA>HIM<SPA>IN<SPA>HISSSLEEP<END><SPA>IT<COM>S<SPA>IRONIC<SPA>HE<SPA>COULD<SPA>SAVE<SPA>OTHERS<SPA>FROM<SPA>DEATH<COM><SPA>BUT<SPA>NOT<SPA>HIMSELF<END><SPA>"
     ]
    }
   ],
   "source": [
    "model.reset()\n",
    "t = 0\n",
    "correct = 0\n",
    "pp = 0\n",
    "for inp_and_tok in tokens.split(20, dim=0):\n",
    "    inps = inp_and_tok[:, :-1, 0]\n",
    "    targets = inp_and_tok[:, -1, 0].type(torch.cuda.LongTensor)\n",
    "    out = model(inps*input_scaling)\n",
    "\n",
    "    # Accuracy\n",
    "    indexes = out.argmax(-1).detach().cpu().numpy()\n",
    "    for i in indexes:\n",
    "        sys.stdout.write(id_to_let[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
